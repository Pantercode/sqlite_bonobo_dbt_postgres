# sqlite_bonobo_dbt_postgres


# Projeto: SQLite ‚Üí Postgres (raw) ‚Üí dbt (silver/gold) ‚Üí Power BI usando Bonobo

Este projeto implementa um pipeline **ETL sem Docker** para extra√ß√£o, carga, transforma√ß√£o e visualiza√ß√£o de dados.  
O objetivo √©:

1. **Extrair** dados de um banco **SQLite**.
2. **Carregar** os dados no **Postgres**, na camada **raw**.
3. **Transformar** os dados com **dbt** nas camadas **silver** (limpeza/tipagem) e **gold** (modelos prontos para BI).
4. **Consumir** os dados no **Power BI**.

---

## üöÄ Fluxo Geral

1. **Bonobo (Python)**  
   - Conecta no SQLite.
   - L√™ todas as tabelas.
   - Carrega no Postgres (schema `raw`).
   
2. **dbt**  
   - Usa os dados do schema `raw` como **source**.
   - Cria tabelas limpas e tipadas na camada `silver`.
   - Gera dimens√µes, fatos e m√©tricas na camada `gold`.

3. **Power BI**  
   - Conecta na camada `gold` do Postgres.
   - Monta dashboards e relat√≥rios.

---

## üìÇ Estrutura do Projeto

<pre>
sqlite-to-postgres-bonobo-dbt/
  data/
    basketball.sqlite        # Arquivo SQLite de origem
  etl/
    __init__.py              # Inicializa√ß√£o do m√≥dulo ETL
    config.py                # Configura√ß√µes e vari√°veis de ambiente
    io_adapters.py           # Fun√ß√µes de conex√£o e leitura/escrita
    transforms.py            # Transforma√ß√µes de dados
    graph.py                 # Defini√ß√£o do grafo Bonobo (pipeline)
  .env                       # Configura√ß√µes de ambiente
  run.py                     # Script principal do ETL
  README.md                  # Documenta√ß√£o do projeto
</pre>



---

## üõ† Tecnologias Utilizadas

- **SQLite** ‚Üí Fonte de dados.
- **Python + Bonobo** ‚Üí Orquestra√ß√£o e carga para Postgres.
- **SQLAlchemy** ‚Üí Conex√£o com bancos.
- **Pandas** ‚Üí Manipula√ß√£o de dados durante o ETL.
- **Postgres** ‚Üí Armazenamento nas camadas `raw`, `silver`, `gold`.
- **dbt-core** ‚Üí Transforma√ß√µes de dados.
- **Power BI** ‚Üí Visualiza√ß√£o de dados.

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

1. **Pr√©-requisitos**
   - Python 3.8+
   - Postgres instalado e rodandoüîÑ Execu√ß√£o do Pipeline

Coloque o arquivo basketball.sqlite na pasta data/.

Crie os schemas no Postgres:

CREATE SCHEMA IF NOT EXISTS raw;
CREATE SCHEMA IF NOT EXISTS silver;
CREATE SCHEMA IF NOT EXISTS gold;


Execute o ETL com:

python run.py


Rode as transforma√ß√µes no dbt:

dbt run --profiles-dir profiles

üìä Estrutura das Camadas

raw ‚Üí Dados brutos, extra√≠dos diretamente do SQLite.

silver ‚Üí Dados limpos e tipados, prontos para an√°lise.

gold ‚Üí M√©tricas e agrega√ß√µes otimizadas para BI.
   - dbt-core e dbt-postgres instalados

2. **Instala√ß√£o dos pacotes**
   ```bash
   pip install bonobo pandas sqlalchemy psycopg2-binary python-dotenv
   pip install dbt-core dbt-postgres



   Configura√ß√£o do .env

SQLITE_PATH=./data/basketball.sqlite
PG_HOST=localhost
PG_PORT=5432
PG_DB=basketball
PG_USER=postgres
PG_PASSWORD=postgres
PG_SCHEMA_RAW=raw

